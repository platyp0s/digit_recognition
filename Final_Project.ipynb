{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project\n",
    "\n",
    "## Optical Character Recognition via Supervised Machine Learning<br/>\n",
    "\n",
    "#### In Optical Character Recognition, we want an algorithm that can work with any sort of image.\n",
    "#### No matter how poor the hand writing, we want a chance at correctly guessing the character.\n",
    "#### The algorithm itself should try to find the structure of the input character.\n",
    "#### We can endeavor to accomplish this by having access to training data.\n",
    "#### Based on that training data, the algorithm can make a determination on the classification of the image.\n",
    "#### We can use the notion of a nearest neighbor classifier to determine which character an image is meant to represent.\n",
    "#### http://scikit-learn.org/stable/modules/neighbors.html#nearest-neighbors-classification \n",
    "#### The 1,797 digit images in the datasets subset of the sklearn module are each represented by 8 by 8 pixels,<br/> meaning 64 pixels or dimensions, where each pixel has a darkness scale of 0 for lightest to 15 for darkest.\n",
    "#### We can think of the individual pixels of each image as presenting a distance.\n",
    "#### The distance from a pixel in one image to the corresponding pixel in another image can be based on the darkness or lightness of each pixel.  \n",
    "#### A pixel of darkness 0 and the corresponding pixel of darkness 0 are closest since they contain the same value.\n",
    "#### A pixel of darkness 15 and the corresponding pixel of darkness 0 are furthest, since they are at opposite ends of the spectrum.\n",
    "#### If we determine an overall image 'distance' based on the corresponding pixel 'distances' between two images,<br/> we can determine how close they are to being the same character.\n",
    "#### If we iterate over enough data, we can assert that the shortest 'distance' to a known character means that the <br/>unknown character should be the same as the charater to which it is nearest.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# allows for in-notebook graph/image generation\n",
    "%matplotlib notebook\n",
    "# used for plotting graphs\n",
    "import matplotlib.pyplot as plt\n",
    "# used for scientific computing\n",
    "import numpy as np\n",
    "\n",
    "# http://scikit-learn.org/stable/auto_examples/datasets/\n",
    "# plot_digits_last_image.html#sphx-glr-auto-examples-datasets-plot-digits-last-image-py\n",
    "# sklearn datasets contains 1797 labeled images of digits\n",
    "# Array digits.images contains the images\n",
    "# Array digits.target contains the 'labels' for the images\n",
    "# Each pixel from digits.images has a number between 0 and 15\n",
    "# representing the darkness of each pixel\n",
    "from sklearn import datasets\n",
    "training_digits = datasets.load_digits()\n",
    "\n",
    "# https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.norm.html\n",
    "# http://stackoverflow.com/questions/1401712/\n",
    "# how-can-the-euclidean-distance-be-calculated-with-numpy#1401828\n",
    "def distance(x, y):\n",
    "    (\"This function returns the Euclidian distance between two points.\"\n",
    "     \"For example, for points x = [0, 0] and y = [3, 4], the function\"\n",
    "     \"first subtracts [3, 4] from [0, 0], yielding point [-3, -4].\"\n",
    "     \"The function then square that point to [9, 16] and sums the\"\n",
    "     \"coordinates 9 + 16 = 25.  Finally, the square root\"\n",
    "     \"of that value is taken: âˆš25 = 5.\"\n",
    "     \"Research suggested the function below as the fastest way of\"\n",
    "     \"calculating Euclidean distance.\")\n",
    "\n",
    "    return np.linalg.norm(x - y)\n",
    "\n",
    "\n",
    "# print the gray scale representation of the digit 9\n",
    "print(training_digits.images[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# https://chrisalbon.com/python/set_the_color_of_a_matplotlib.html\n",
    "# plot the image for digit 9\n",
    "plt.figure()\n",
    "plt.imshow(training_digits.images[9], cmap=plt.cm.binary)\n",
    "plt.show()\n",
    "# There does indeed appear to be a correspondence between\n",
    "# the color of an individiual pixel and the number 0-15\n",
    "# representing that pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We can also check if the image is indeed properly labeled.\n",
    "\n",
    "print(\"Label of training_digits.images[9]: {}\".format(training_digits.target[9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the label is indeed 9\n",
    "# Well, that is fine and dandy, but what does this have to do with machine learning\n",
    "# and supervised learning?\n",
    "# Good point.\n",
    "# We can now choose a subset of datasets.load_digits(), which we have saved under\n",
    "# the variable name training_digits, and create our training arrays from that subset.\n",
    "\n",
    "# since the digits 0 through 9 repeat, making the training digits 0-9 makes sense\n",
    "Train_digits = training_digits.data[0:10]\n",
    "Train_labels = training_digits.target[0:10]\n",
    "\n",
    "# We can choose a random number from the dataset and pretend we do not have its label.\n",
    "Test_digit = training_digits.data[300]\n",
    "\n",
    "# We can plot training_digits.data[300] to visually determine what it is\n",
    "plt.figure()\n",
    "plt.imshow(training_digits.images[300], cmap = plt.cm.binary)\n",
    "plt.show()\n",
    "# https://chrisalbon.com/python/set_the_color_of_a_matplotlib.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# It seems to be a 7 but it sure it ugly.  Maybe a 3?\n",
    "# We can test if our distance function and the data of the \n",
    "# 10 image subarray can correctly classify this 9.\n",
    "\n",
    "# initialize a list of zeros\n",
    "distances = [0 for i in range(len(Train_digits))]\n",
    "\n",
    "# calculate the distance between each digit and the test digit\n",
    "for i in range(len(Train_digits)):\n",
    "    distances[i] = distance(Train_digits[i], Test_digit)\n",
    "\n",
    "# https://docs.scipy.org/doc/numpy/reference/generated/numpy.argmin.html\n",
    "# determine the index of the label with the closest distance\n",
    "# argmin gives the list index of the smallest value\n",
    "closest_label = np.argmin(distances)\n",
    "# check the label determined based on the distances calculated\n",
    "print(Train_labels[closest_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let us check the actual label of our test number to be sure.\n",
    "print(training_digits.target[300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# It seems the program did all right.\n",
    "# But we really should test it against more than one image.\n",
    "# After all, I myself could not tell if the image was a 7 or a 3 initially!\n",
    "# Keeping track of the errors made would be ideal to determine the actual failure\n",
    "# rate and to determine if there is improvement or degradation with larger\n",
    "# data sets.\n",
    "\n",
    "errors = 0\n",
    "\n",
    "distances = [0 for i in range(len(Train_digits))]\n",
    "\n",
    "for i in range(0,100):\n",
    "    Test_digit = training_digits.data[i]\n",
    "    for j in range (len(Train_digits)):\n",
    "        distances[j] = distance(Train_digits[j], Test_digit)\n",
    "    closest_label = np.argmin(distances)\n",
    "    if Train_labels[closest_label] != training_digits.target[i]:\n",
    "        errors += 1\n",
    "\n",
    "# print the percentage of correct predictions\n",
    "print(\"Correct percentage: {0:.2f}%\".format((100 - errors)/ 100*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Wow, that is not so great.\n",
    "# Only 77% correct.\n",
    "# What can be done to get it better?\n",
    "# Well, expanding the training set to more than 10 digits \n",
    "# would seem like a logical step.\n",
    "# Let us double to 20.\n",
    "\n",
    "Train_digits = training_digits.data[0:20]\n",
    "Train_labels = training_digits.target[0:20]\n",
    "\n",
    "# The remainder of the code should be the same.\n",
    "\n",
    "errors = 0\n",
    "\n",
    "distances = [0 for i in range(len(Train_digits))]\n",
    "\n",
    "for i in range(0,100):\n",
    "    Test_digit = training_digits.data[i]\n",
    "    for j in range (len(Train_digits)):\n",
    "        distances[j] = distance(Train_digits[j], Test_digit)\n",
    "    closest_label = np.argmin(distances)\n",
    "    if Train_labels[closest_label] != training_digits.target[i]:\n",
    "        errors += 1\n",
    "\n",
    "# print the number of errors you made\n",
    "print(\"Correct percentage: {0:.2f}%\".format((100 - errors)/ 100*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We have improvement!\n",
    "# Maybe we should double the size of training set again \n",
    "# to see even more improvement?\n",
    "\n",
    "Train_digits = training_digits.data[0:40]\n",
    "Train_labels = training_digits.target[0:40]\n",
    "\n",
    "# The remainder of the code should be the same.\n",
    "\n",
    "errors = 0\n",
    "\n",
    "distances = [0 for i in range(len(Train_digits))]\n",
    "\n",
    "for i in range(0,100):\n",
    "    Test_digit = training_digits.data[i]\n",
    "    for j in range (len(Train_digits)):\n",
    "        distances[j] = distance(Train_digits[j], Test_digit)\n",
    "    closest_label = np.argmin(distances)\n",
    "    if Train_labels[closest_label] != training_digits.target[i]:\n",
    "        errors += 1\n",
    "\n",
    "# print the number of errors you made\n",
    "print(\"Correct percentage: {0:.2f}%\".format((100 - errors)/ 100*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Even better!\n",
    "# Maybe increasing the training set to 50 will yield no errors.\n",
    "\n",
    "Train_digits = training_digits.data[0:50]\n",
    "Train_labels = training_digits.target[0:50]\n",
    "\n",
    "# The remainder of the code should be the same.\n",
    "\n",
    "errors = 0\n",
    "\n",
    "distances = [0 for i in range(len(Train_digits))]\n",
    "\n",
    "for i in range(0,100):\n",
    "    Test_digit = training_digits.data[i]\n",
    "    for j in range (len(Train_digits)):\n",
    "        distances[j] = distance(Train_digits[j], Test_digit)\n",
    "    closest_label = np.argmin(distances)\n",
    "    if Train_labels[closest_label] != training_digits.target[i]:\n",
    "        errors += 1\n",
    "\n",
    "# print the number of errors you made\n",
    "print(\"Correct percentage: {0:.2f}%\".format((100 - errors)/ 100*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Close to perfect!\n",
    "# How about we increase to 100, but just to be sure,\n",
    "# we test digits other than 0 through 99 and change\n",
    "# the digits we want to test to say 100 through 199?\n",
    "\n",
    "Train_digits = training_digits.data[0:100]\n",
    "Train_labels = training_digits.target[0:100]\n",
    "\n",
    "# The remainder of the code should be the same.\n",
    "\n",
    "errors = 0\n",
    "\n",
    "distances = [0 for i in range(len(Train_digits))]\n",
    "\n",
    "for i in range(100,200):\n",
    "    Test_digit = training_digits.data[i]\n",
    "    for j in range (len(Train_digits)):\n",
    "        distances[j] = distance(Train_digits[j], Test_digit)\n",
    "    closest_label = np.argmin(distances)\n",
    "    if Train_labels[closest_label] != training_digits.target[i]:\n",
    "        errors += 1\n",
    "\n",
    "# print the number of errors you made\n",
    "print(\"Correct percentage: {0:.2f}%\".format((100 - errors)/ 100*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Interesting!\n",
    "# So even though we increased the training set\n",
    "# to a high value, there are some characters\n",
    "# we could not correctly predict in this new\n",
    "# range of tested numbers.\n",
    "# How about if we kick it up to 1000 and try \n",
    "# these same numbers from 100 to 199?\n",
    "\n",
    "Train_digits = training_digits.data[0:1000]\n",
    "Train_labels = training_digits.target[0:1000]\n",
    "\n",
    "# The remainder of the code should be the same.\n",
    "\n",
    "errors = 0\n",
    "\n",
    "distances = [0 for i in range(len(Train_digits))]\n",
    "\n",
    "for i in range(100,200):\n",
    "    Test_digit = training_digits.data[i]\n",
    "    for j in range (len(Train_digits)):\n",
    "        distances[j] = distance(Train_digits[j], Test_digit)\n",
    "    closest_label = np.argmin(distances)\n",
    "    if Train_labels[closest_label] != training_digits.target[i]:\n",
    "        errors += 1\n",
    "\n",
    "# print the number of errors you made\n",
    "print(\"Correct percentage: {0:.2f}%\".format((100 - errors)/ 100*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfection has been achieved!\n",
    "So we have learned that we can teach the program to calculate better<br/>\n",
    "by providing it with more more and more training data, but we also learned<br/>\n",
    "that a new batch of testing data can show diminished program performance,<br/>\n",
    "so the larger the training data set, the safer we are."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
